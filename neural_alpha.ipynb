{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1087it [00:07, 147.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train_year = 2018\n",
    "train_stock = {}\n",
    "test_stock = {}\n",
    "\n",
    "folder_pth = os.readlink(\"data/symlink\")\n",
    "\n",
    "for idx, path in tqdm(enumerate(glob(f\"{folder_pth}/*.csv\"))):\n",
    "    curr_df = pd.read_csv(path)\n",
    "    stock_name = path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    train_df = curr_df.loc[curr_df['date'].apply(lambda x: int(x.split('-')[0]) < train_year)]\n",
    "    test_df = curr_df.loc[curr_df['date'].apply(lambda x: int(x.split('-')[0]) >= train_year)]\n",
    "    \n",
    "    if len(train_df):\n",
    "        train_stock[stock_name] = train_df\n",
    "    \n",
    "    if len(test_df):\n",
    "        test_stock[stock_name] = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_stock = ['2330']\n",
    "\n",
    "subset_train_stock = train_stock #{_:train_stock[_] for _ in subset_stock}\n",
    "subset_test_stock = test_stock #{_:test_stock[_] for _ in subset_stock}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>證券代號</th>\n",
       "      <th>開盤價</th>\n",
       "      <th>最高價</th>\n",
       "      <th>最低價</th>\n",
       "      <th>收盤價</th>\n",
       "      <th>成交股數</th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-04-23</td>\n",
       "      <td>9939</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.60</td>\n",
       "      <td>30.70</td>\n",
       "      <td>30.80</td>\n",
       "      <td>3818579.0</td>\n",
       "      <td>32.757224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-04-24</td>\n",
       "      <td>9939</td>\n",
       "      <td>30.80</td>\n",
       "      <td>31.10</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.60</td>\n",
       "      <td>5984851.0</td>\n",
       "      <td>32.544515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-04-25</td>\n",
       "      <td>9939</td>\n",
       "      <td>30.60</td>\n",
       "      <td>30.60</td>\n",
       "      <td>29.80</td>\n",
       "      <td>30.00</td>\n",
       "      <td>4290668.0</td>\n",
       "      <td>31.906387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-04-26</td>\n",
       "      <td>9939</td>\n",
       "      <td>30.25</td>\n",
       "      <td>30.25</td>\n",
       "      <td>29.55</td>\n",
       "      <td>29.75</td>\n",
       "      <td>3748365.0</td>\n",
       "      <td>31.640500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-04-27</td>\n",
       "      <td>9939</td>\n",
       "      <td>29.75</td>\n",
       "      <td>29.80</td>\n",
       "      <td>29.35</td>\n",
       "      <td>29.35</td>\n",
       "      <td>2315366.0</td>\n",
       "      <td>31.215082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>9939</td>\n",
       "      <td>57.50</td>\n",
       "      <td>57.80</td>\n",
       "      <td>57.30</td>\n",
       "      <td>57.50</td>\n",
       "      <td>351603.0</td>\n",
       "      <td>103.170459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>9939</td>\n",
       "      <td>57.40</td>\n",
       "      <td>57.40</td>\n",
       "      <td>56.70</td>\n",
       "      <td>56.70</td>\n",
       "      <td>723297.0</td>\n",
       "      <td>101.735044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>9939</td>\n",
       "      <td>56.70</td>\n",
       "      <td>57.10</td>\n",
       "      <td>56.70</td>\n",
       "      <td>57.00</td>\n",
       "      <td>299195.0</td>\n",
       "      <td>102.273325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>9939</td>\n",
       "      <td>57.00</td>\n",
       "      <td>57.40</td>\n",
       "      <td>56.50</td>\n",
       "      <td>57.00</td>\n",
       "      <td>348260.0</td>\n",
       "      <td>102.273325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>9939</td>\n",
       "      <td>57.00</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.00</td>\n",
       "      <td>57.50</td>\n",
       "      <td>562051.0</td>\n",
       "      <td>103.170459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2652 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  證券代號    開盤價    最高價    最低價    收盤價       成交股數   adj_close\n",
       "0     2007-04-23  9939  31.00  31.60  30.70  30.80  3818579.0   32.757224\n",
       "1     2007-04-24  9939  30.80  31.10  30.00  30.60  5984851.0   32.544515\n",
       "2     2007-04-25  9939  30.60  30.60  29.80  30.00  4290668.0   31.906387\n",
       "3     2007-04-26  9939  30.25  30.25  29.55  29.75  3748365.0   31.640500\n",
       "4     2007-04-27  9939  29.75  29.80  29.35  29.35  2315366.0   31.215082\n",
       "...          ...   ...    ...    ...    ...    ...        ...         ...\n",
       "2647  2017-12-25  9939  57.50  57.80  57.30  57.50   351603.0  103.170459\n",
       "2648  2017-12-26  9939  57.40  57.40  56.70  56.70   723297.0  101.735044\n",
       "2649  2017-12-27  9939  56.70  57.10  56.70  57.00   299195.0  102.273325\n",
       "2650  2017-12-28  9939  57.00  57.40  56.50  57.00   348260.0  102.273325\n",
       "2651  2017-12-29  9939  57.00  57.90  57.00  57.50   562051.0  103.170459\n",
       "\n",
       "[2652 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stock[list(train_stock.keys())[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.95s/it]\n"
     ]
    }
   ],
   "source": [
    "past_window, future_window = 60, 20\n",
    "full_window = past_window + future_window\n",
    "buy_fee = 0.001425\n",
    "sell_fee = 0.003 + buy_fee\n",
    "\n",
    "data = {}\n",
    "\n",
    "for curr_phase, curr_data in tqdm({'train': subset_train_stock, 'test': subset_test_stock}.items()):\n",
    "    data[curr_phase] = {'x': [], 'y': [], 'y_with_cost': [], 'name': [], 'date': []}\n",
    "\n",
    "    for idx, (stock_name, stock_df) in enumerate(curr_data.items()):\n",
    "        close_array = stock_df['adj_close'].to_numpy()\n",
    "        volume_array = stock_df['成交股數'].to_numpy()\n",
    "        date_array = stock_df['date'].to_numpy()\n",
    "\n",
    "        window_index = np.arange(\n",
    "            close_array.shape[0] - full_window + 1\n",
    "        ).reshape(-1, 1) + np.arange(full_window)\n",
    "\n",
    "        close_window_array = close_array[window_index]\n",
    "        volume_window_array = volume_array[window_index]\n",
    "        date_window_array = date_array[window_index]\n",
    "\n",
    "        close_anchor = close_window_array[:, 1:past_window]\n",
    "        volume_anchor = (\n",
    "            np.log(volume_window_array[:, 1:past_window] + 1) - np.log(volume_window_array[:, :1]) + 1\n",
    "        ) / np.log(volume_window_array[:, :1] + 1)\n",
    "        date_anchor = date_window_array[:, -1]\n",
    "\n",
    "        raw_leave = (\n",
    "            close_window_array[:, -future_window: ] - close_window_array[:, past_window - 1: past_window]\n",
    "        ) / close_window_array[:, past_window - 1: past_window]\n",
    "        sell_price = close_window_array[:, -future_window:] * (1 - sell_fee)\n",
    "        buy_price = close_window_array[:, past_window-1:past_window] * (1 + buy_fee)\n",
    "        real_leave = (sell_price - buy_price) / buy_price\n",
    "\n",
    "        data[curr_phase]['x'].append(close_anchor.reshape(close_anchor.shape[0], close_anchor.shape[1], 1))\n",
    "        data[curr_phase]['y'].append(raw_leave)\n",
    "        data[curr_phase]['y_with_cost'].append(real_leave)\n",
    "        data[curr_phase]['name'].append(np.array([stock_name]*close_anchor.shape[0]))\n",
    "        data[curr_phase]['date'].append(date_anchor)\n",
    "\n",
    "    data[curr_phase]['x'] = np.concatenate(data[curr_phase]['x'])\n",
    "    data[curr_phase]['y'] = np.concatenate(data[curr_phase]['y'])\n",
    "    data[curr_phase]['y_with_cost'] = np.concatenate(data[curr_phase]['y_with_cost'])\n",
    "    data[curr_phase]['name'] = np.concatenate(data[curr_phase]['name'])\n",
    "    data[curr_phase]['date'] = np.concatenate(data[curr_phase]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563611, 59, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"test\"]['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiable_spearman(pred, target):\n",
    "    pred_rank = torchsort.soft_rank(pred)\n",
    "    target_rank = torchsort.soft_rank(target)\n",
    "    pred_n = pred_rank - pred_rank.mean()\n",
    "    target_n = target_rank - target_rank.mean()\n",
    "    pred_n = pred_n / pred_n.norm()\n",
    "    target_n = target_n / target_n.norm()\n",
    "    corr = (pred_n * target_n).sum()\n",
    "    return corr\n",
    "\n",
    "\n",
    "class MAMA(nn.Module):\n",
    "    def __init__(self, max_history=30, n_alpha=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_alpha = n_alpha\n",
    "        self.alpha_linear = nn.Linear(max_history, n_alpha * 2, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        alpha_weight = self.alpha_linear.weight.softmax(-1)\n",
    "        alpha = nn.functional.linear(x, alpha_weight)\n",
    "        alpha = (alpha[:, :self.n_alpha] - alpha[:, self.n_alpha:]).tanh()\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "969it [01:05, 14.72it/s]\n"
     ]
    }
   ],
   "source": [
    "tr_x = []\n",
    "tr_y = []\n",
    "te_x = []\n",
    "te_y = []\n",
    "\n",
    "for i, stock_name in tqdm(enumerate(train_stock.keys())):\n",
    "    tr_x.append(data['train']['x'][data['train']['name'] == stock_name].squeeze().astype('float32'))\n",
    "    tr_y.append(data['train']['y_with_cost'][data['train']['name'] == stock_name, -1].astype('float32'))\n",
    "    te_x.append(data['test']['x'][data['test']['name'] == stock_name].squeeze().astype('float32'))\n",
    "    te_y.append(data['test']['y_with_cost'][data['test']['name'] == stock_name, -1].astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((862, 59), (862,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x[-1].shape, tr_y[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MAMA(max_history=past_window-1, n_alpha=1).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2613, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.030494062505831598\n",
      "-0.03555363092955463\n",
      "-0.03953002655276283\n",
      "-0.04253687478060823\n",
      "-0.044885372572892775\n",
      "-0.04684892512718072\n",
      "-0.048544764311617035\n",
      "-0.05007038740835261\n",
      "-0.05138449727195259\n",
      "-0.052442589964067914\n",
      "-0.05329685356449701\n",
      "-0.053974708052959015\n",
      "-0.054493584344187565\n",
      "-0.05491284498275941\n",
      "-0.05522666905619304\n",
      "-0.05548755900710398\n",
      "-0.05570324485683266\n",
      "-0.05588955406142328\n",
      "-0.05602964786408994\n",
      "-0.05613334865082955\n",
      "-0.05621546815628603\n",
      "-0.0562834687612329\n",
      "-0.05634091786645695\n",
      "-0.056390441177553194\n",
      "-0.05643394590583481\n",
      "-0.05647289111012001\n",
      "-0.056507276391965636\n",
      "-0.056537071221904066\n",
      "-0.05656325480873313\n",
      "-0.05658702393626108\n",
      "-0.05660959760782427\n",
      "-0.0566299157008102\n",
      "-0.05664713713566324\n",
      "-0.05666229861665429\n",
      "-0.056675953624392324\n",
      "-0.056688444142160656\n",
      "-0.05669931143724578\n",
      "-0.056709038684653046\n",
      "-0.05671798906054048\n",
      "-0.05672633739020599\n",
      "-0.05673415867539201\n",
      "-0.05674158992143434\n",
      "-0.05674902935463347\n",
      "-0.056756307984033354\n",
      "-0.05676317159545399\n",
      "-0.056769580208101494\n",
      "-0.05677552079607447\n",
      "-0.05678086796265107\n",
      "-0.05678559945148038\n",
      "-0.056789822319606116\n",
      "-0.0567936177954887\n",
      "-0.05679708826370053\n",
      "-0.05680025987347763\n",
      "-0.056803238915132455\n",
      "-0.05680603622057609\n",
      "-0.05680862380628031\n",
      "-0.056811083944839254\n",
      "-0.05681322832648057\n",
      "-0.05681520602240547\n",
      "-0.05681710024409946\n",
      "-0.05681872773714656\n",
      "-0.05682035570005983\n",
      "-0.05682179359844102\n",
      "-0.05682309970855078\n",
      "-0.05682429253585998\n",
      "-0.05682549569505902\n",
      "-0.056826480531558525\n",
      "-0.05682749440112623\n",
      "-0.05682848768416404\n",
      "-0.0568293250258147\n",
      "-0.05683018848642619\n",
      "-0.056830922612498475\n",
      "-0.0568316289651668\n",
      "-0.05683237409975545\n",
      "-0.05683301387054863\n",
      "-0.05683358223033325\n",
      "-0.05683415951553283\n",
      "-0.05683472179348789\n",
      "-0.05683524969456308\n",
      "-0.05683574878987428\n",
      "-0.056836207730068956\n",
      "-0.05683670331369817\n",
      "-0.05683710175012291\n",
      "-0.05683752556064265\n",
      "-0.05683791037371153\n",
      "-0.05683833400966836\n",
      "-0.05683869459032936\n",
      "-0.05683897762601163\n",
      "-0.05683932454571305\n",
      "-0.056839661393987384\n",
      "-0.05683991900751881\n",
      "-0.05684024254287813\n",
      "-0.05684056240749056\n",
      "-0.056840783010921235\n",
      "-0.05684105317532186\n",
      "-0.05684133185906541\n",
      "-0.056841518837209865\n",
      "-0.056841736257540486\n",
      "-0.05684196240385423\n",
      "-0.056842169244687185\n",
      "-0.05684242856167872\n",
      "-0.056842574128646586\n",
      "-0.05684277932620939\n",
      "-0.05684296035227511\n",
      "-0.056843134669382296\n",
      "-0.05684334521760474\n",
      "-0.056843487835624734\n",
      "-0.05684365709989848\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 11\u001b[0m     curr_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mdifferentiable_spearman\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m_\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_tr_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m curr_loss\n\u001b[1;32m     16\u001b[0m     epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mdifferentiable_spearman\u001b[0;34m(pred, target)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdifferentiable_spearman\u001b[39m(pred, target):\n\u001b[1;32m      2\u001b[0m     pred_rank \u001b[38;5;241m=\u001b[39m torchsort\u001b[38;5;241m.\u001b[39msoft_rank(pred)\n\u001b[0;32m----> 3\u001b[0m     target_rank \u001b[38;5;241m=\u001b[39m \u001b[43mtorchsort\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoft_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     pred_n \u001b[38;5;241m=\u001b[39m pred_rank \u001b[38;5;241m-\u001b[39m pred_rank\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      5\u001b[0m     target_n \u001b[38;5;241m=\u001b[39m target_rank \u001b[38;5;241m-\u001b[39m target_rank\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/git/neural_alpha/.venv/lib/python3.10/site-packages/torchsort/ops.py:48\u001b[0m, in \u001b[0;36msoft_rank\u001b[0;34m(values, regularization, regularization_strength)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regularization \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregularization\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSoftRank\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization_strength\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/neural_alpha/.venv/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/git/neural_alpha/.venv/lib/python3.10/site-packages/torchsort/ops.py:100\u001b[0m, in \u001b[0;36mSoftRank.forward\u001b[0;34m(ctx, tensor, regularization, regularization_strength)\u001b[0m\n\u001b[1;32m     98\u001b[0m w \u001b[38;5;241m=\u001b[39m _arange_like(tensor, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     99\u001b[0m theta \u001b[38;5;241m=\u001b[39m tensor \u001b[38;5;241m*\u001b[39m ctx\u001b[38;5;241m.\u001b[39mscale\n\u001b[0;32m--> 100\u001b[0m s, permutation \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m inv_permutation \u001b[38;5;241m=\u001b[39m _inv_permutation(permutation)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mregularization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    \n",
    "    for stock_tr_x, stock_tr_y in zip(tr_x, tr_y):\n",
    "    \n",
    "        out = model(torch.tensor(stock_tr_x, dtype=torch.float32).to(device))\n",
    "\n",
    "        loss = 0\n",
    "        for _ in range(out.shape[-1]):\n",
    "            curr_loss = -differentiable_spearman(\n",
    "                out[:, _:_+1].t(),\n",
    "                torch.tensor(stock_tr_y, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            )\n",
    "            loss += curr_loss\n",
    "            epoch_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     tr_out \u001b[38;5;241m=\u001b[39m model(\u001b[43mtr_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device))\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      5\u001b[0m     te_out \u001b[38;5;241m=\u001b[39m model(te_x\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    tr_out = model(tr_x.to(device)).cpu()\n",
    "    te_out = model(te_x.to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tr_y[:100])\n",
    "plt.plot(tr_out[:100].sum(-1))\n",
    "plt.plot(tr_out[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(te_out.squeeze().numpy(), te_y.numpy(), bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in [-1, -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    print(_, ((te_y[te_out.sum(-1) > _] > 0) * 1.).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_y[te_out[:, 0] > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((te_y[te_out[:, 0] > 0.1] > 0) * 1.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((te_y[te_out[:, 0] > -1] > 0) * 1.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_y[te_out[:, 0] < -0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(te_y)\n",
    "plt.plot(te_out.sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.alpha_linear.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.alpha_linear.weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.alpha_linear.weight[0]).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.alpha_linear.weight[2]).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.alpha_linear.weight[1] / model.alpha_temp[1]).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(4, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsl = nn.Linear(30, 10, bias=False)\n",
    "temp = nn.Parameter(torch.ones(10, 1)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsl.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = nn.functional.linear(a, wsl.weight)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = nn.functional.linear(a, (wsl.weight / temp).softmax(-1))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o[:, 5:] - o[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma 上下穿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today - weighted_sum_of_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stock['2330']['成交股數']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stock['2330']['收盤價'][:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
